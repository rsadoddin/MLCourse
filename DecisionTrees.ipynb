{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "DecisionTrees.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFh89YMk0Zph"
      },
      "source": [
        "# Lab: Decision Trees\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2owTxYuZ0Zpj"
      },
      "source": [
        "## The \"German Credit\" Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYSOh_qu0Zpj"
      },
      "source": [
        "### Dataset Details"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tl5-m3G0Zpk"
      },
      "source": [
        "This dataset has two classes (these would be considered labels in Machine Learning terms) to describe the worthiness of a personal loan: \"Good\" or \"Bad\". There are predictors related to attributes, such as: checking account status, duration, credit history, purpose of the loan, amount of the loan, savings accounts or bonds, employment duration, installment rate in percentage of disposable income, personal information, other debtors/guarantors, residence duration, property, age, other installment plans, housing, number of existing credits, job information, number of people being liable to provide maintenance for, telephone, and foreign worker status.\n",
        "\n",
        "Many of these predictors are discrete and have been expanded into several 0/1 indicator variables (a.k.a. they have been one-hot-encoded).\n",
        "\n",
        "This dataset has been kindly provided by Professor Dr. Hans Hofmann of the University of Hamburg, and can also be found on the UCI Machine Learning Repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WpbQ4yd0Zpl"
      },
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2ggRDl-0Zpn"
      },
      "source": [
        "## Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kkgp1h9L0Zpn"
      },
      "source": [
        " As we have learned in the previous lectures, Decision Trees as a family of algorithms (irrespective to the particular implementation) are powerful algorithms that can produce models with a predictive accuracy higher than that produced by linear models, such as Linear or Logistic Regression. Primarily, this is due to the fact the DT's can model nonlinear relationships, and also have a number of tuning paramters, that allow for the practicioner to achieve the best possible model. An added bonus is the ability to visualize the trained Decision Tree model, which allows for some insight into how the model has produced the predictions that it has. One caveat here, to keep in mind, is that sometimes, due to the size of the dataset (both in the sense of the number of records, as well as the number of features), the visualization might prove to be very large and complex, increasing the difficulty of interpretation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaKm8p1j0Zpo"
      },
      "source": [
        "To give you a very good example of how Decision Trees can be visualized and interpreted, we would strongly recommend that, before continuing on with solving the problems in this Mini Project, you take the time to read this fanstastic, detailed and informative blog post: http://explained.ai/decision-tree-viz/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hO7P01P0Zpo"
      },
      "source": [
        "## Building Your First Decision Tree Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VNfmgOX0Zpp"
      },
      "source": [
        "So, now it's time to jump straight into the heart of the matter. Your first task, is to build a Decision Tree model, using the aforementioned \"German Credit\" dataset, which contains 1,000 records, and 62 columns (one of them presents the labels, and the other 61 present the potential features for the model.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7XVSVJa0Zpq"
      },
      "source": [
        "For this task, you will be using the scikit-learn library, which comes already pre-installed with the Anaconda Python distribution. In case you're not using that, you can easily install it using pip."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqCMXuie0Zpr"
      },
      "source": [
        "Before embarking on creating your first model, we would strongly encourage you to read the short tutorial for Decision Trees in scikit-learn (http://scikit-learn.org/stable/modules/tree.html), and then dive a bit deeper into the documentation of the algorithm itself (http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFTjE6nI0Zps"
      },
      "source": [
        "Also, since you want to be able to present the results of your model, we suggest you take a look at the tutorial for accuracy metrics for classification models (http://scikit-learn.org/stable/modules/model_evaluation.html#classification-report) as well as the more detailed documentation (http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html).\n",
        "\n",
        "Finally, an *amazing* resource that explains the various classification model accuracy metrics, as well as the relationships between them, can be found on Wikipedia: https://en.wikipedia.org/wiki/Confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4YDp1Uw0Zps"
      },
      "source": [
        "(Note: as you've already learned in the Logistic Regression mini project, a standard practice in Machine Learning for achieving the best possible result when training a model is to use hyperparameter tuning, through Grid Search and k-fold Cross Validation. We strongly encourage you to use it here as well, not just because it's standard practice, but also becuase it's not going to be computationally to intensive, due to the size of the dataset that you're working with. Our suggestion here is that you split the data into 70% training, and 30% testing. Then, do the hyperparameter tuning and Cross Validation on the training set, and afterwards to a final test on the testing set.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okpD_BrG0Zpt"
      },
      "source": [
        "### Now we pass the torch onto you! You can start building your first Decision Tree model! :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ksoxfdc0Zpt"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr85ZKo40Zpu"
      },
      "source": [
        "# Your code here! :)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQzXZ7T70Zpu"
      },
      "source": [
        "### After you've built the best model you can, now it's time to visualize it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWtROrQS0Zpu"
      },
      "source": [
        "Rememeber that amazing blog post from a few paragraphs ago, that demonstrated how to visualize and interpret the results of your Decision Tree model. We've seen that this can perform very well, but let's see how it does on the \"German Credit\" dataset that we're working on, due to it being a bit larger than the one used by the blog authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4437-iO10Zpu"
      },
      "source": [
        "First, we're going to need to install their package. If you're using Anaconda, this can be done easily by running:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4Krb26F0Zpu"
      },
      "source": [
        "! pip install dtreeviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXOzOGSG0Zpu"
      },
      "source": [
        "If for any reason this way of installing doesn't work for you straight out of the box, please refer to the more detailed documentation here: https://github.com/parrt/dtreeviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q12646Zr0Zpu"
      },
      "source": [
        "Now you're ready to visualize your Decision Tree model! Please feel free to use the blog post for guidance and inspiration!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMS1uFnF0Zpw"
      },
      "source": [
        "# Your code here! :)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}